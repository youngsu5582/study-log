## Nginx

- 테코톡 링크 : https://www.youtube.com/watch?v=6FAwAXXj5N0

Nginx 를 알아보기에 앞서 역사로 돌아간다.

### 1995 년 - Apache Http Server

Nginx 이전에 Apache HTTP Server 가 있었다.

HTTP Server 는 매우 혁신적이였다.
직접 만들지 않아도 되고, 버그도 없고, 확장성이 좋은 웹 서버였다.

- 요청이 들어오면 새로운 Process 생성 (기존 UNIX 계열 네트워크 형태를 활용)
- Process 를 생성해야 하니 시간이 걸리므로 미리 만드는 pre-fork 방식
  -> 모두 할당되면, 추가 생성

개발이 쉽고, 확장성이 좋아 많은 사람들이 사용했다.

### 1999 년 - C10K

컴퓨터가 보급되기 시작하며, 서버가 처리해야 하는 요청 양이 늘어나기 시작했다.
- 이때 당시, HTTP 프로토콜의 진화로, `Keep-Alive` 를 통한 연결을 유지도 하기 시작했다.

서버에 이상한 문제가 생기기 시작했다!

더 이상 커넥션을 형성하지 못하는 문제 발생
=> C10K ( Connection 10K )

> `동시 연결된 커넥션 수`와 `초당 요청 처리수`는 다르다.
> - 동시 연결 커넥션 수 : 요청을 처리하기 위해 서버가 클라이언트와 연결하고 있는 수
    > (이미 연결되어 있다면? 유지를 함 - Keep-Alive)
> - 초당 요청 처리 수 : 서버가 초당 처리할 수 있는 양

HW 의 문제가 아니였다. 그때당시 HW 는 어마무시하게 성장 하는 중

- 매번 프로세스를 생성해 메모리가 부족
- 확장성이 너무 좋아, 확장 프로그램들이 붙으며 프로세스의 크기도 증가
- 프로세스간 컨텍스트 스위칭으로 부하증가! ( 매번 프로세스 생성하므로 )

=> 이때부터, 스을슬 Nginx 가 등장하기 시작했다.

### 2002 년 - Nginx

Nginx 는 처음에는 Apache Http Server 의 보완재였다.

앞단에 붙여서, 정적 요청은 Nginx 가 + 동적 요청은 HTTP Server 에 보냈다.

Nginx 는 Master / Worker Process 로 이루어져 있다.

- Master Process : 설정 파일을 읽고, 설정에 맞게 워커 프로세스를 생성하는 프로세스
- Worker Process : 실제 일을 하는 프로세스, 각자 지정된 listen 소켓 배정 받음 - 새로운 요청 들어오면 커넥션 생성 및 처리

Worker Process 가 커넥션 하나만 처리하지 않는다!
-> 다른 커넥션으로 요청 받거나, 생성하거나 등등 일을 처리해준다.

=> 이런 새로운 요청을 처리하는 것을 Nginx 에선 `이벤트` 라고 한다.

O.S 커널이 큐 형식으로 워커 프로세스에게 전달
-> 워커 프로세스가 처리할 때 까지 비동기 방식으로 대기

워커 프로세스는 쉬지않고, 계속해서 일을 한다!
( Apache 에 비해, 방치된 프로세스 없이 매우 효율적 )

- 그러면 Disk IO 같이 오래 걸리는 작업을 해야 한다면?
  -> Nginx 는 오래 걸리는 작업을 수행하는 Thread Pool 을 따로 만들어놈
  -> 해당 스레드 풀에 작업을 위임하고 큐 안에 있는 다른 이벤트 처리하러 감

> 보통 워커 프로세스는 CPU 코어 수 만큼 or ( -1? ) 생성
> 프로세스를 바꾸는 횟수를 대폭 줄임 ( 컨텍스트 스위칭 사용 줄임 )

=> 이게 바로 Event Driven 구조이다!

그렇기에 모듈을 직접 만들기는 까다롭다. ( 잘 돌아가는걸 박살 낼 수 있으므로 )

하지만, 장점이 너무 뛰어났다.

- 동시 커넥션 양 최소 10배 증가 - 일반적 100배, 1000배 증가
- 동일 커넥션 수일때 속도 2배 향상

추가로,?

- 동적 설정이 가능

설정 방식을 변경하면?

1. 마스터 프로세스가 설정에 맞는 워커 프로세스를 따로 생성
2. 기존에 있던 워커 프로세스가 더 이상 커넥션 형성하지 않도록 함
3. 기존 워커 프로세스가 처리하던 이벤트가 모두 끝나면, 해당 프로세스들 종료

> 일종의 로드 밸런서와 그냥 동일하다!

Nginx 가 여러 동시 커넥션을 관리하는 도중에 뒷단에 서버가 추가되어도? 문제 없다.
( 초당 수십번을 해도 문제 없을 정도 ㅇ.ㅇ)

=> 하지만, 초창기에는 인기가 별로 없었다. 2007년 까지도 여전히 Apahce 가 압도적 1위 ( 순위권에도 없었음 )

### 2008년 - 스마트폰의 출시

스마트폰은 동시 커넥션을 훨씬 더 많이 생성하게 된 계기가 되었다.
유투브를 보다가, 인스타그램을 보다가, 등등등 이런 정보를 실시간으로 받고 싶어했다.

추가로, 브라우저 역시도 리소스를 빨리 가져오기 위해 여러 TCP 커넥션을 동시 형성

한계를 느끼고, 빠르게 대기업부터 교체를 하기 시작했다.

Apache 도 MPMs 라는 모듈을 도입은 했다.

- Multi Processing Module : 성능 향상을 위해 사용할 수 있는 대안, 워커가 요청을 처리하는 형식

-> 그럼에도, 성능 테스트에서 Nginx 가 압도적으로 이김 - 초당 요청 처리 수, 메모리 사용량 등

=> 하지만, 여전히 인기가 나쁘지 않다. 대립 관계 자체가 아님

### 2021, 2025??

여전히 다양한 방법으로 웹 서버의 가속기 역할을 해준다.

- Nginx SSL 터미네이션 : Client 와는 HTTPS 통신, Server 와는 HTTP 통신 ( 같은 네트워크에 있으니, HTTP 통신으로도 가능 )
- 캐싱 : 서버로 받은 응답 캐싱 - 클라이언트에 가깝게 배치


이외에도 HSTS, CORS, TCP/UDP 커넥션 부하 분산, HTTP/2 등등 다양하다고 하낟.

- HSTS : 웹 사이트 접속할 때, 강제로 HTTPS Protocol 을 사용해 접속하게 하는 기술
